{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. MarioAI - DQN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NknPAK7VrCsn",
        "colab_type": "code",
        "outputId": "63508796-b4ae-42b8-e148-234e90fab429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcMe1bMDripg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "mkdir -p \"/content/gdrive/My Drive/development/ai/2-mario-ai-dqn/video\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvi5P-5EvKmY",
        "colab_type": "text"
      },
      "source": [
        "**Pre-reading material:**\n",
        "\n",
        "Deep Q Network:\n",
        "1. https://www.intel.ai/demystifying-deep-reinforcement-learning/\n",
        "1. https://towardsdatascience.com/reinforcement-learning-w-keras-openai-dqns-1eed3a5338c \n",
        "1. https://pylessons.com/CartPole-DDQN/\n",
        "\n",
        "> Note: Article #2 has an error: `target = self.target_model.predict(state)` \n",
        ">\n",
        "> should be: `target = self.model.predict(state)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtFQgm46CVPC",
        "colab_type": "text"
      },
      "source": [
        "**Important notes I noticed while training:**\n",
        "\n",
        "From link #5:\n",
        "1. https://towardsdatascience.com/from-zero-to-flagpole-hero-ead14fc46fba\n",
        "\n",
        "> With everything setup, I ran the same code I used for the Atari games but instead targeted the first level of Super Mario Bros. and… nothing happened. I waited an hour, but Mario only figured out that he gets killed by the first Goomba in the level, and he generally doesn’t like getting killed, so a better tactic is to just stand in place and safely wait for time to expire.\n",
        "\n",
        "From link #6: \n",
        "1. https://web.archive.org/web/20190630025508/https://www.statworx.com/de/blog/using-reinforcement-learning-to-play-super-mario-bros-on-nes-using-tensorflow/\n",
        "\n",
        "About 10,000 episodes and 20 hours of compute on Google Cloud was needed to learn the first level!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JwvTkyNliHX",
        "colab_type": "code",
        "outputId": "ac247385-97c9-4dc4-a79c-c47d125f881b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash\n",
        "pip3 install gym\n",
        "pip3 install gym-super-mario-bros\n",
        "pip3 install keras==2.3.1\n",
        "pip3 install matplotlib\n",
        "apt-get update\n",
        "apt-get -y install ffmpeg\n",
        "apt-get -y install libsm6 libxext6"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.15.4)\n",
            "Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.2.2)\n",
            "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.17.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from gym) (4.1.2.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym) (0.16.0)\n",
            "Requirement already satisfied: gym-super-mario-bros in /usr/local/lib/python3.6/dist-packages (7.3.0)\n",
            "Requirement already satisfied: nes-py>=8.0.0 in /usr/local/lib/python3.6/dist-packages (from gym-super-mario-bros) (8.1.1)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros) (1.17.4)\n",
            "Requirement already satisfied: gym>=0.10.9 in /usr/local/lib/python3.6/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros) (0.15.4)\n",
            "Requirement already satisfied: tqdm>=4.19.5 in /usr/local/lib/python3.6/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros) (4.28.1)\n",
            "Requirement already satisfied: pyglet>=1.3.2 in /usr/local/lib/python3.6/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.10.9->nes-py>=8.0.0->gym-super-mario-bros) (1.3.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from gym>=0.10.9->nes-py>=8.0.0->gym-super-mario-bros) (4.1.2.30)\n",
            "Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.10.9->nes-py>=8.0.0->gym-super-mario-bros) (1.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym>=0.10.9->nes-py>=8.0.0->gym-super-mario-bros) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.3.2->nes-py>=8.0.0->gym-super-mario-bros) (0.16.0)\n",
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.3.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.17.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.17.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (42.0.2)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libsm6 is already the newest version (2:1.2.2-1).\n",
            "libxext6 is already the newest version (2:1.3.3-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JhwyrUisAji",
        "colab_type": "text"
      },
      "source": [
        "**OpenAI's Gym toolkit documentation:**\n",
        "\n",
        "http://gym.openai.com/docs/#observations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybfHFrASx64P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VIDEO_MONITOR_DIR = \"/content/gdrive/My Drive/development/ai/2-mario-ai-dqn/video/\"\n",
        "VIDEO_MONITOR_DIR = \"/content/video/\"\n",
        "STATE_SAVE_DIR = \"/content/gdrive/My Drive/development/ai/2-mario-ai-dqn\"\n",
        "\n",
        "# how many states/steps to keep in memory for training sampling\n",
        "MEMORY_CAPACITY = 20000\n",
        "# number of steps to fill memory before starting to train\n",
        "BURN_IN_STEPS = 5000\n",
        "# how many frames (previous + last one) to keep in history per state\n",
        "# a few frames are needed in order for the network to understand movement/motion\n",
        "FRAME_SKIP_STACK_SIZE = 4\n",
        "# how many states to use per training iteration\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "# how many steps to wait until updating target model\n",
        "TARGET_UPDATE_FREQUENCY = 500\n",
        "# epsilon settings for DQN\n",
        "EPSILON_START = .99\n",
        "EPSILON_START = .01\n",
        "EPSILON_MIN = .05\n",
        "EPSILON_DECAY = 0.99995\n",
        "# gradient descent!\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# during frame capture, we will resize frame down to 84x84 pixels\n",
        "SHAPE_SIZE = (84, 84, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH4OcuFzMDj1",
        "colab_type": "text"
      },
      "source": [
        "Lets setup the environment to play Super Mario Bros! We will import the gym_super_mario_bros library to run our game.\n",
        "\n",
        "The video recording (gym.wrappers.Monitor) lib requires the close() call to flush the video data onto disk, but close() causes issues with the mario env to not be rerunnable. Lets fix that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwj-X4D3EkTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import gym\n",
        "from gym import Wrapper\n",
        "from gym.spaces import Box\n",
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT, RIGHT_ONLY\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import numpy as np\n",
        "\n",
        "class NoCloseFix(Wrapper):\n",
        "  # allow create_env to be rerunnable. monitor needs close to write mp4 file...\n",
        "  def close(self):\n",
        "    self.env.reset()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QGa7vRlYk56",
        "colab_type": "text"
      },
      "source": [
        "Original NES video frames are 240x256 RGB pixels. We can downscale to reduce the amount of inputs our network needs and still provide accurate results! Lets also remove color information since that isn't needed to beat the game."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSSIzI9rYiiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomViewport(Wrapper):\n",
        "  def __init__(self, env=None):\n",
        "    super(CustomViewport, self).__init__(env)\n",
        "    # nes resolution: (240 vertical, 256 horizontal, 3 rgb)\n",
        "    self.observation_space = Box(low=0, high=1, shape=(240, 256, 1))\n",
        "    self.observation_space = Box(low=0, high=1, shape=SHAPE_SIZE)\n",
        "\n",
        "  def step(self, action):\n",
        "    state, reward, done, info = self.env.step(action)\n",
        "    state = self.process_frame(state)\n",
        "    return state, reward, done, info\n",
        "  \n",
        "  # process_frame for monitoring video\n",
        "  def render(self, mode):\n",
        "    state = self.env.render(mode)\n",
        "    state = self.process_frame(state)\n",
        "    # convert grayscale back to 3 channel rgb:\n",
        "    # ([1,2],)*2 = ([1, 2], [1, 2])\n",
        "    state = np.stack((state,)*3, axis=-1)\n",
        "    return (state * 255).astype(np.uint8)\n",
        "\n",
        "  def reset(self):\n",
        "    return self.process_frame(self.env.reset())\n",
        "  \n",
        "  def process_frame(self, frame):\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "    frame = cv2.resize(frame, (SHAPE_SIZE[0], SHAPE_SIZE[1]), interpolation=cv2.INTER_AREA)\n",
        "    return frame / 255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-G8J--TYN8R",
        "colab_type": "text"
      },
      "source": [
        "A single frame is not enough to take action upon. We need to whether we are moving to make a decision and that requires a few frames:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnYsMOL1LRQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSkipFrame(Wrapper):\n",
        "  def __init__(self, env, skip=4):\n",
        "    super(CustomSkipFrame, self).__init__(env)\n",
        "    self.observation_space = Box(low=0, high=1, shape=(SHAPE_SIZE[0], SHAPE_SIZE[1], FRAME_SKIP_STACK_SIZE))\n",
        "    self.skip = skip\n",
        "\n",
        "  def step(self, action):\n",
        "    total_reward = 0.0\n",
        "    state, reward, done, info = self.env.step(action)\n",
        "    state = state.reshape(state.shape[0], state.shape[1], 1) #60x64x1\n",
        "    states = state\n",
        "\n",
        "    for i in range(self.skip - 1):\n",
        "      if not done:\n",
        "        state, reward, done, info = self.env.step(action)\n",
        "        state = state.reshape(state.shape[0], state.shape[1], 1) #60x64x1\n",
        "        total_reward += reward\n",
        "        states = np.append(state, states[:, :, :], axis=2)\n",
        "      else:\n",
        "        total_reward += reward\n",
        "        states = np.append(state, states[:, :, :], axis=2)\n",
        "    \n",
        "    return states.astype(np.float32), total_reward, done, info\n",
        "\n",
        "  def reset(self):\n",
        "      state = self.env.reset()\n",
        "      states = np.stack((state,)*FRAME_SKIP_STACK_SIZE, axis=-1)\n",
        "      return states\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "400_cQ6dI2Po",
        "colab_type": "text"
      },
      "source": [
        "The gym-super-mario-bros has its own reward function:\n",
        "\n",
        "https://github.com/Kautenja/gym-super-mario-bros#reward-function\n",
        "\n",
        "We will add some more incentives to the environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJG_FBDtIz8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomReward(Wrapper):\n",
        "  def __init__(self, env=None):\n",
        "    super(CustomReward, self).__init__(env)\n",
        "    self._current_score = 0\n",
        "\n",
        "  def step(self, action):\n",
        "    state, reward, done, info = self.env.step(action)\n",
        "    reward += (info['score'] - self._current_score) / 40.0\n",
        "    self._current_score = info['score']\n",
        "    if done:\n",
        "      if info['flag_get']:\n",
        "        reward += 350.0\n",
        "      else:\n",
        "        reward -= 50.0\n",
        "    return state, reward / 10.0, done, info\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV0CL9nlIgHM",
        "colab_type": "text"
      },
      "source": [
        "Lets combine all the previous wrappers to produce a usable environment for our AI model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8nyVVrqIeYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_env():\n",
        "  world = 1\n",
        "  stage = 1\n",
        "  env = gym_super_mario_bros.make(\"SuperMarioBros-{}-{}-v0\".format(world, stage))\n",
        "  \n",
        "  # lets allow our environment to have full movement\n",
        "  actions = COMPLEX_MOVEMENT\n",
        "  env = JoypadSpace(env, actions)\n",
        "\n",
        "  print(env.observation_space.shape)\n",
        "  env = NoCloseFix(env)\n",
        "  env = gym.wrappers.Monitor(env, VIDEO_MONITOR_DIR, video_callable=lambda episode_id: True, force = False)\n",
        "  env = CustomViewport(env)\n",
        "  env = CustomSkipFrame(env)\n",
        "  env = CustomReward(env)\n",
        "\n",
        "  return env\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WnUC8nVZhTU",
        "colab_type": "text"
      },
      "source": [
        "Now we start defining the real model that learns how to play mario:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb3Vv_h54LQm",
        "colab_type": "code",
        "outputId": "67f4f4b6-9df5-4173-d69b-88ba147e5ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.layers import Conv2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from collections import deque\n",
        "import random\n",
        "\n",
        "class DQN:\n",
        "  def dummy(self):\n",
        "    pass\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yClIYuAi6LH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(DQN):\n",
        "\n",
        "  def __init__(self, env):\n",
        "    self.env = env\n",
        "    self.memory = deque(maxlen=MEMORY_CAPACITY)\n",
        "    \n",
        "    self.epsilon = EPSILON_START\n",
        "    self.epsilon_min = EPSILON_MIN\n",
        "    self.epsilon_decay = EPSILON_DECAY\n",
        "    self.learning_rate = LEARNING_RATE\n",
        "    self.gamma = 0.85\n",
        "    self.tau = .125\n",
        "    self.step_count = 1\n",
        "    self.target_update_frequency = TARGET_UPDATE_FREQUENCY\n",
        "\n",
        "    self.model = self.create_model()\n",
        "    self.target_model = self.create_model()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR_lc-SfaAW5",
        "colab_type": "text"
      },
      "source": [
        "The is the actual neural network that predicts how much total reward will be produced based off the current input video frames. Output is the reward per possible action (left, right, up, down, etc...):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znz_UbVt2I6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "class DQN(DQN):\n",
        "\n",
        "  def create_model(self):\n",
        "    input_shape = self.env.observation_space.shape\n",
        "    input_shape = (input_shape[0], input_shape[1], FRAME_SKIP_STACK_SIZE)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, 8, strides=4, activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
        "    model.add(Conv2D(64, 4, strides=2, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(Conv2D(64, 3, strides=1, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(self.env.action_space.n))\n",
        "\n",
        "    model.compile(loss=\"mean_squared_error\", optimizer=Adam(lr=self.learning_rate))\n",
        "    return model\n",
        "  \n",
        "  def save_model(self, fn):\n",
        "    self.model.save(fn)\n",
        "\n",
        "  def load_model(self, fn):\n",
        "    self.model = load_model(fn)\n",
        "    target_weights = self.model.get_weights()\n",
        "    self.target_model.set_weights(target_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8CqQHNdaYS0",
        "colab_type": "text"
      },
      "source": [
        "In the early stages of the agent's lifetime, the agent hasnt experienced/learned about rewards for each possible action. The epsilon variable forces the agent to choose a random action. Over time the value of epsilon decreases to allow the agent to make its own decisions when it has enough training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcwK_tWH2Nfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(DQN):\n",
        "  \n",
        "  def act_train(self, state):\n",
        "    self.epsilon *= self.epsilon_decay\n",
        "    self.epsilon = max(self.epsilon_min, self.epsilon)\n",
        "    if np.random.random() < self.epsilon:\n",
        "      # print(\"random action: %f\" % (self.epsilon))\n",
        "      return self.env.action_space.sample()\n",
        "    return np.argmax(self.model.predict(state)[0])\n",
        "  \n",
        "  def act_test(self, state):\n",
        "    return np.argmax(self.target_model.predict(state)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY10kjY0awJI",
        "colab_type": "text"
      },
      "source": [
        "As we progress through the environment, we will memorize the actions we have taken and the reward we received. We use that to define the error function for the neural network.\n",
        "\n",
        "Make note that the target value is not just the immediate reward for the current action, but a prediction of what will be rewarded for future possible actions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpqdbybrV2t-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(DQN):\n",
        "  \n",
        "  def memorize(self, state, action, reward, new_state, done):\n",
        "    self.memory.append([state, action, reward, new_state, done])\n",
        "    self.step_count += 1\n",
        "  \n",
        "  def replay(self):\n",
        "    if self.step_count < BURN_IN_STEPS:\n",
        "      return\n",
        "    if len(self.memory) < TRAIN_BATCH_SIZE: \n",
        "      return\n",
        "    \n",
        "    samples = random.sample(self.memory, TRAIN_BATCH_SIZE)\n",
        "    batch_state = np.zeros((TRAIN_BATCH_SIZE, SHAPE_SIZE[0], SHAPE_SIZE[1], FRAME_SKIP_STACK_SIZE))\n",
        "    batch_new_state = np.zeros((TRAIN_BATCH_SIZE, SHAPE_SIZE[0], SHAPE_SIZE[1], FRAME_SKIP_STACK_SIZE))\n",
        "    \n",
        "    for i in range(TRAIN_BATCH_SIZE):\n",
        "      state, action, reward, new_state, done = samples[i]\n",
        "      batch_state[i] = state\n",
        "      batch_new_state[i] = new_state\n",
        "    \n",
        "    # do batch prediction to save speed\n",
        "    # predict Q-values for starting state using the main network\n",
        "    target = self.model.predict(batch_state)\n",
        "    Q_future = self.target_model.predict(batch_new_state)\n",
        "    \n",
        "    for i in range(TRAIN_BATCH_SIZE):\n",
        "      state, action, reward, new_state, done = samples[i]\n",
        "      # target = self.model.predict(state)\n",
        "      if done:\n",
        "        target[i][action] = reward\n",
        "      else:\n",
        "        # Q_future = max(self.target_model.predict(new_state)[0])\n",
        "        target[i][action] = reward + max(Q_future[i]) * self.gamma\n",
        "    \n",
        "    self.model.fit(batch_state, target, batch_size=TRAIN_BATCH_SIZE, epochs=1, verbose=0)\n",
        "    \n",
        "  def target_train(self):\n",
        "    if self.step_count < BURN_IN_STEPS:\n",
        "      return\n",
        "    if (self.step_count - BURN_IN_STEPS) % self.target_update_frequency == 0:\n",
        "      print(\"Updating training weights...\")\n",
        "      weights = self.model.get_weights()\n",
        "      target_weights = self.target_model.get_weights()\n",
        "      for i in range(len(target_weights)):\n",
        "        target_weights[i] = weights[i] * self.tau + target_weights[i] * (1 - self.tau)\n",
        "      self.target_model.set_weights(target_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bppeKWAOb4sl",
        "colab_type": "text"
      },
      "source": [
        "Here is the code that actually runs the environment and the model together. It will take time to train..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsqQ61ipuk15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import gc\n",
        "import json\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "def model_load(dqn_agent):\n",
        "  print(\"Loading existing model...\")\n",
        "  dqn_agent.load_model(STATE_SAVE_DIR + \"/mario-ai.h5\")\n",
        "  with open(STATE_SAVE_DIR + \"/mario-ai.json\") as f:\n",
        "    model_info = json.load(f)\n",
        "  return model_info\n",
        "\n",
        "def model_save(dqn_agent, info):\n",
        "  print(\"Saving state...\")\n",
        "  dqn_agent.save_model(STATE_SAVE_DIR + \"/mario-ai.h5\")\n",
        "  with open(STATE_SAVE_DIR + \"/mario-ai.json\", \"w\") as f:\n",
        "    f.write(json.dumps(info))\n",
        "\n",
        "def run_episode(env, dqn_agent, run_info, train, episode, total_step):\n",
        "  episode_reward = 0.0\n",
        "  stage_step = 0\n",
        "\n",
        "  # http://gym.openai.com/docs/#observations\n",
        "  # state = np.ndarray = image data for game\n",
        "  state = env.reset()\n",
        "  # In Keras, need to reshape to add an extra dimension for number of samples: (num_samples, w, h, channels)\n",
        "  state = state.reshape(1, state.shape[0], state.shape[1], state.shape[2])  #1*80*80*4\n",
        "\n",
        "  while (True):\n",
        "    if train:\n",
        "      action = dqn_agent.act_train(state)\n",
        "    else:\n",
        "      action = dqn_agent.act_test(state)\n",
        "    \n",
        "    new_state, reward, done, info = env.step(action)\n",
        "    new_state = new_state.reshape(1, new_state.shape[0], new_state.shape[1], new_state.shape[2])  #1*80*80*4\n",
        "    episode_reward += reward\n",
        "\n",
        "    if stage_step % 50 == 0:\n",
        "      # print(\"[Time=%3d][Steps={total:%d|episode:%d|stage:%d}][x=%d][y=%d][Reward={total:%f|step:%f}][action=%s][epsilon=%f]\" \n",
        "      #   % (info[\"time\"], total_step, episode, stage_step, info[\"x_pos\"], info[\"y_pos\"], episode_reward, reward, COMPLEX_MOVEMENT[action], dqn_agent.epsilon))\n",
        "      print(\"[Time=%3d][Steps={total:%d|episode:%d|stage:%d}][x=%d][y=%d][Reward={total:%f|step:%f}][epsilon=%f]\" \n",
        "        % (info[\"time\"], total_step, episode, stage_step, info[\"x_pos\"], info[\"y_pos\"], episode_reward, reward, dqn_agent.epsilon))\n",
        "\n",
        "    if train:\n",
        "      dqn_agent.memorize(state, action, reward, new_state, done)\n",
        "      dqn_agent.replay() # internally iterates default (prediction) model\n",
        "      dqn_agent.target_train() # iterates target model\n",
        "\n",
        "      if total_step > BURN_IN_STEPS and (total_step - BURN_IN_STEPS + 1) % 5000 == 0:\n",
        "        model_save(dqn_agent, run_info)\n",
        "    \n",
        "    state = new_state\n",
        "    total_step += 1\n",
        "    stage_step += 1\n",
        "\n",
        "    if done:\n",
        "      break\n",
        "  \n",
        "  return stage_step, episode_reward, info[\"x_pos\"]\n",
        "\n",
        "def main(env, load, train):\n",
        "  info = {}\n",
        "  info[\"hist_reward\"] = []\n",
        "  info[\"hist_x_pos\"] = []\n",
        "  info[\"hist_episode\"] = []\n",
        "  print(env.observation_space.shape)\n",
        "\n",
        "  dqn_agent = DQN(env=env)\n",
        "  total_step = 0\n",
        "  episode = 0\n",
        "\n",
        "  if load:\n",
        "    info = model_load(dqn_agent)\n",
        "    episode = max(info[\"hist_episode\"]) + 1\n",
        "\n",
        "  while (True):\n",
        "    stage_step, reward, x_pos = run_episode(env, dqn_agent, info, train, episode, total_step)\n",
        "    print('[Episode=%d][Reward=%f][x=%d]' % (episode, reward, x_pos))\n",
        "\n",
        "    if total_step > BURN_IN_STEPS:\n",
        "      info[\"hist_reward\"].append(reward)\n",
        "      info[\"hist_x_pos\"].append(int(x_pos))\n",
        "      info[\"hist_episode\"].append(int(episode))\n",
        "\n",
        "      display.clear_output(wait=True)\n",
        "      display.display(plt.gcf())\n",
        "      plt.clf()\n",
        "      fig, (ax1, ax2) = plt.subplots(2)\n",
        "      ax1.plot(info[\"hist_episode\"], info[\"hist_x_pos\"])\n",
        "      ax2.plot(info[\"hist_episode\"], info[\"hist_reward\"])\n",
        "      plt.show()\n",
        "\n",
        "      episode += 1\n",
        "    \n",
        "    total_step += stage_step\n",
        "\n",
        "  del dqn_agent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YVvvBknZoIy",
        "colab_type": "text"
      },
      "source": [
        "Lets clean up any left over video files from a previous run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_YMXVCLjiRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "# clean up video folder before each run!\n",
        "shutil.rmtree(VIDEO_MONITOR_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyQkrjp5Zskd",
        "colab_type": "text"
      },
      "source": [
        "Now we start training!:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QRrCnNzhbY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n",
        "\n",
        "try:\n",
        "  env = create_env()\n",
        "  main(env, load=False, train=True)\n",
        "finally:\n",
        "  env.close()\n",
        "  keras.backend.clear_session()\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfrSOdtkZxwv",
        "colab_type": "text"
      },
      "source": [
        "After training, we can run a test against our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-NxsCOsIxzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  env = create_env()\n",
        "  main(env, load=True, train=False)\n",
        "finally:\n",
        "  env.close()\n",
        "  keras.backend.clear_session()\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb40xj4CZ26E",
        "colab_type": "text"
      },
      "source": [
        "Here is the results of our training on about 12000 episodes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swfwxw64pXFe",
        "colab_type": "code",
        "outputId": "8acd0f3c-c975-45ec-fe00-083ab3742270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "with open(STATE_SAVE_DIR + \"/mario-ai.json\") as f:\n",
        "  info = json.load(f)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2)\n",
        "ax1.plot(info[\"hist_episode\"], info[\"hist_x_pos\"])\n",
        "ax2.plot(info[\"hist_episode\"], info[\"hist_reward\"])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqh8m62zX9q4",
        "colab_type": "text"
      },
      "source": [
        "Video of DQN agent completing the first level: [link](https://drive.google.com/file/d/1B0pc3Hfj1DneOXxMNPJyKLvCDg7nVWN3/view?usp=sharing)"
      ]
    }
  ]
}